{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zyJ25uz0kSaw"
   },
   "source": [
    "# **Assignment-2 for CS60075: Natural Language Processing**\n",
    "\n",
    "#### Instructor : Prof. Sudeshna Sarkar\n",
    "\n",
    "#### Teaching Assistants : Alapan Kuila, Aniruddha Roy, Prithwish Jana, Udit Dharmin Desai\n",
    "\n",
    "#### Date of Announcement: 15th Sept, 2021\n",
    "#### Deadline for Submission: 11.59pm on Wednesday, 22nd Sept, 2021 \n",
    "#### Submit this .ipynb file, named as `<Your_Roll_Number>_Assn2_NLP_A21.ipynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ao1nhg9RknmF"
   },
   "source": [
    "The central idea of this assignment is to use Naive Bayes classifier and LSTM based classifier and compare the models by accuracy on IMDB dataset.  This dataset consists of 50k movie reviews (25k positive, 25k negative). You can download the dataset from https://www.kaggle.com/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ONM5Q4SCe9Mr"
   },
   "source": [
    "Please submit with outputs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ElRkQElWUMjG"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import keras\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "fhHRim2AUm4z"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Probably my all-time favorite movie, a story o...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I sure would like to see a resurrection of a u...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>This show was an amazing, fresh &amp; innovative i...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Encouraged by the positive comments about this...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>If you like original gut wrenching laughter yo...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
       "5  Probably my all-time favorite movie, a story o...  positive\n",
       "6  I sure would like to see a resurrection of a u...  positive\n",
       "7  This show was an amazing, fresh & innovative i...  negative\n",
       "8  Encouraged by the positive comments about this...  negative\n",
       "9  If you like original gut wrenching laughter yo...  positive"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load the IMDB dataset. You can load it using pandas as dataframe\n",
    "df = pd.read_csv(\"IMDB Dataset.csv\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lK_Hn2f6VMP7"
   },
   "source": [
    "# Preprocessing\n",
    "PrePrecessing that needs to be done on lower cased corpus\n",
    "\n",
    "1. Remove html tags\n",
    "2. Remove URLS\n",
    "3. Remove non alphanumeric character\n",
    "4. Remove Stopwords\n",
    "5. Perform stemming and lemmatization\n",
    "\n",
    "You can use regex from re. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "5B5lHZPsVOXv"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\bolkbam\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\bolkbam\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\bolkbam\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one reviewer mentioned watching 1 oz episode h...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wonderful little production filming technique ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thought wonderful way spend time hot summer we...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically family little boy jake think zombie ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter mattei love time money visually stunnin...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>probably time favorite movie story selflessnes...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sure would like see resurrection dated seahunt...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>show amazing fresh innovative idea 70 first ai...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>encouraged positive comment film looking forwa...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>like original gut wrenching laughter like movi...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  one reviewer mentioned watching 1 oz episode h...  positive\n",
       "1  wonderful little production filming technique ...  positive\n",
       "2  thought wonderful way spend time hot summer we...  positive\n",
       "3  basically family little boy jake think zombie ...  negative\n",
       "4  petter mattei love time money visually stunnin...  positive\n",
       "5  probably time favorite movie story selflessnes...  positive\n",
       "6  sure would like see resurrection dated seahunt...  positive\n",
       "7  show amazing fresh innovative idea 70 first ai...  negative\n",
       "8  encouraged positive comment film looking forwa...  negative\n",
       "9  like original gut wrenching laughter like movi...  positive"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess(corpus):\n",
    "    corpus = corpus.lower()\n",
    "    corpus = re.compile(r'<[^>]+>').sub(\"\",corpus)   #removing html tags\n",
    "    corpus = re.sub(r\"http\\S+\", \"\", corpus)\n",
    "    corpus = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', corpus) #removing URLS \n",
    "    corpus = re.sub(r\"[^a-zA-Z0-9]+\", \" \", corpus) #removing non alphanumeric character\n",
    "    tokenized = word_tokenize(corpus)\n",
    "    filtered_list = [word for word in tokenized if not word in stop_words] #stopwords removal\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lem_words = [lemmatizer.lemmatize(word,pos=\"n\") for word in filtered_list] #lemmatization\n",
    "    s = ' '.join(lem_words)\n",
    "    return s \n",
    "\n",
    "df[\"review\"] = df[\"review\"].apply(preprocess) \n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "DyaSkfcvYGXk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg length of sentences:  119.56162\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print Statistics of Data like avg length of sentence , proposition of data w.r.t class labels\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sent_len = []\n",
    "\n",
    "for sent in df.review[0:]:\n",
    "    sent_tokenized = word_tokenize(sent)  #tokenizing each sentences \n",
    "    length = len(sent_tokenized)\n",
    "    sent_len.append(length)\n",
    "   \n",
    "\n",
    "avg = sum(sent_len)/len(sent_len)\n",
    "print(\"Avg length of sentences: \", avg)\n",
    "\n",
    "\n",
    "#From the plot we can observe that most of the sentences length is around 100\n",
    "sns.displot(sent_len)\n",
    "plt.xlim([0, 500]);\n",
    "plt.xlabel('Token count');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 2 artists>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Counting the number of positive and negative reviews\n",
    "## Result -> Pos = Neg = 25K , Observe the bar graph below\n",
    "pos=0\n",
    "neg=0\n",
    "for w in df.sentiment[0:]:\n",
    "    if w == 'positive':\n",
    "        pos = pos + 1\n",
    "    else:\n",
    "        neg = neg + 1\n",
    "plt.bar(['Positve','Negative'],[pos,neg])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_FkJ-e2pUwun"
   },
   "source": [
    "# Naive Bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "eVq-mN28U_J4"
   },
   "outputs": [],
   "source": [
    "# get reviews column from df\n",
    "reviews = df[\"review\"]\n",
    "\n",
    "# get labels column from df\n",
    "labels = df[\"sentiment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Ljo5NquhXTXr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['negative' 'positive']\n",
      "[1 1 1 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Use label encoder to encode labels. Convert to 0/1\n",
    "encoder = LabelEncoder()\n",
    "encoded_labels = encoder.fit_transform(labels)\n",
    "\n",
    "# print(enc.classes_)\n",
    "print(encoder.classes_)\n",
    "print(encoded_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "wzG-C_EVWWET"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "# Split the data into train and test (80% - 20%). \n",
    "# Use stratify in train_test_split so that both train and test have similar ratio of positive and negative samples.\n",
    "\n",
    "train_sentences, test_sentences, train_labels, test_labels = train_test_split(reviews,encoded_labels, test_size=0.2, random_state=0 ,stratify = encoded_labels)\n",
    "print(len(train_sentences))\n",
    "print(len(test_sentences))\n",
    "# train_sentences, test_sentences, train_labels, test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bz1YdsSkiWCX"
   },
   "source": [
    "Here there are two approaches possible for building vocabulary for the naive Bayes.\n",
    "1. Take the whole data (train + test) to build the vocab. In this way while testing there is no word which will be out of vocabulary.\n",
    "2. Take the train data to build vocab. In this case, some words from the test set may not be in vocab and hence one needs to perform smoothing so that one the probability term is not zero.\n",
    " \n",
    "You are supposed to go by the 2nd approach.\n",
    " \n",
    "Also building vocab by taking all words in the train set is memory intensive, hence you are required to build vocab by choosing the top 2000 - 3000 frequent words in the training corpus.\n",
    "\n",
    "> $ P(x_i | w_j) = \\frac{ N_{x_i,w_j}\\, +\\, \\alpha }{ N_{w_j}\\, +\\, \\alpha*d} $\n",
    "\n",
    "\n",
    "$N_{x_i,w_j}$ : Number of times feature $x_i$ appears in samples of class $w_j$\n",
    "\n",
    "$N_{w_j}$ : Total count of features in class $w_j$\n",
    "\n",
    "$\\alpha$ : Parameter for additive smoothing. Here consider $\\alpha$ = 1\n",
    "\n",
    "$d$ : Dimentionality of the feature vector  $x = [x_1,x_2,...,x_d]$. In our case its the vocab size.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "1cllNfGmUr77"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 3000)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# Use Count vectorizer to get frequency of the words\n",
    "'''\n",
    "max_features parameter : If not None, build a vocabulary that only consider the top max_features ordered by term frequency across the corpus.\n",
    "vec = CountVectorizer(max_features = 3000)\n",
    "X = vec.fit_transform(Sentence_list)\n",
    "'''\n",
    "vec = CountVectorizer(max_features = 3000)\n",
    "X = vec.fit_transform(train_sentences)\n",
    "V = X.toarray()\n",
    "Vocab = vec.vocabulary_   #vocabulary of top 3000 frequent words\n",
    "V.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for counting occurrences of top 3000 words in the training sentences/reviews \n",
    "def word_count(reviews,lbl,vocab):\n",
    "    freqs = {}\n",
    "    for rev,lb in zip(reviews,lbl):\n",
    "        word_list = word_tokenize(rev) #tokenizing reviews\n",
    "        for word in word_list:\n",
    "            if word in vocab.keys():  # if current word is in vocabulary \n",
    "                pair = (word,lb)      # creating key -> tuple of word and label\n",
    "                if pair in freqs:     # if key already present, increase the count\n",
    "                    freqs[pair] += 1  # else add it to the dictionary with count 1 \n",
    "                else:\n",
    "                    freqs[pair] = 1\n",
    "    return freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1849849\n",
      "1832542\n"
     ]
    }
   ],
   "source": [
    "freqs = word_count(train_sentences,train_labels,Vocab) \n",
    "\n",
    "Np = 0   # count of features in positive reviewed sentences\n",
    "Nn = 0   # count of features in negative reviewed sentences\n",
    "for word in Vocab.keys() :\n",
    "    Np += freqs.get((word,1))\n",
    "    Nn += freqs.get((word,0))\n",
    "print(Np)\n",
    "print(Nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "qzRvPjWaWUnm"
   },
   "outputs": [],
   "source": [
    "# Use laplace smoothing for words in test set not present in vocab of train set\n",
    "# Implemented below in the model itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "iE7pxWIYW1z0"
   },
   "outputs": [],
   "source": [
    "# Build the model. Don't use the model from sklearn\n",
    "\n",
    "def naive_bayes(words,feature_size,N_pos,N_neg,freqs,Vocab):\n",
    "    ppos = 0\n",
    "    pneg = 0\n",
    "    for word in words:\n",
    "        if word in Vocab.keys():\n",
    "            ppos += np.log((freqs.get((word,1))+1)/(N_pos + feature_size)) # ppos = (ppos) * (freqs.get((word,1),0)+1/(N_pos+feature_size))\n",
    "            pneg += np.log((freqs.get((word,0))+1)/(N_neg + feature_size)) # pneg = (pneg) * (freqs.get((word,0),0)+1/(N_neg+feature_size))\n",
    "          \n",
    "        else :\n",
    "            ppos +=  np.log(1/(N_pos+feature_size)) \n",
    "            pneg += np.log(1/(N_neg+feature_size))  \n",
    "          \n",
    "    ppos += np.log(N_pos/(N_pos+N_neg))                                   # ppos *= (N_pos/(N_pos+N_neg))\n",
    "    pneg += np.log(N_neg/(N_pos+N_neg))                                   # pneg *= (N_neg/(N_pos+N_neg)) \n",
    "\n",
    "    \n",
    "    if ppos>pneg:\n",
    "        return 1\n",
    "    else :\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "AtQSl1zvW4DD"
   },
   "outputs": [],
   "source": [
    "# Test the model on test set and report Accuracy\n",
    "\n",
    "N = 3000                        # total count of features = Vocab size \n",
    "yh = []\n",
    "for sent in test_sentences:\n",
    "    words = word_tokenize(sent)\n",
    "    yh_i = naive_bayes(words,N,Np,Nn,freqs,Vocab)\n",
    "    yh.append(yh_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8439"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = test_labels.tolist()\n",
    "y_h = np.array(yh)\n",
    "error = np.mean(np.absolute(y_h-test_labels))\n",
    "accuracy = 1-error\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WlNql0acU7sa"
   },
   "source": [
    "# *LSTM* based Classifier\n",
    "\n",
    "Use the above train and test splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "SkqnvbUOXoN0"
   },
   "outputs": [],
   "source": [
    "# Hyperparameters of the model\n",
    "vocab_size = 3000 # choose based on statistics\n",
    "oov_tok = '<OOK>'\n",
    "embedding_dim = 100\n",
    "max_length = 200 # choose based on statistics, for example 150 to 200\n",
    "padding_type='post'\n",
    "trunc_type='post'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "UeycEg9nZAOF"
   },
   "outputs": [],
   "source": [
    "# tokenize sentences\n",
    "tokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(train_sentences)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "# convert train dataset to sequence and pad sequences\n",
    "train_sequences = tokenizer.texts_to_sequences(train_sentences)\n",
    "train_padded = pad_sequences(train_sequences, padding='post', maxlen=max_length)\n",
    "\n",
    "# convert Test dataset to sequence and pad sequences\n",
    "test_sequences = tokenizer.texts_to_sequences(test_sentences)\n",
    "test_padded = pad_sequences(test_sequences, padding='post', maxlen=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "Mtw3w895ZP39"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 200, 100)          300000    \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 128)               84480     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 24)                3096      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 25        \n",
      "=================================================================\n",
      "Total params: 387,601\n",
      "Trainable params: 387,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model initialization\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "    keras.layers.Bidirectional(keras.layers.LSTM(64)),\n",
    "    keras.layers.Dense(24, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# compile model\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "skmaDJMnZTzc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 217s 189ms/step - loss: 0.3987 - accuracy: 0.8218 - val_loss: 0.3514 - val_accuracy: 0.8615\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 200s 178ms/step - loss: 0.2936 - accuracy: 0.8809 - val_loss: 0.3242 - val_accuracy: 0.8725\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 198s 176ms/step - loss: 0.2459 - accuracy: 0.9036 - val_loss: 0.3054 - val_accuracy: 0.8777\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 196s 174ms/step - loss: 0.2182 - accuracy: 0.9149 - val_loss: 0.3137 - val_accuracy: 0.8723\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 201s 178ms/step - loss: 0.1883 - accuracy: 0.9281 - val_loss: 0.3246 - val_accuracy: 0.8852\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "history = model.fit(train_padded, train_labels, \n",
    "                    epochs=num_epochs, verbose=1, \n",
    "                    validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "TjEhWEr5Zq7M"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.87      0.88      5000\n",
      "           1       0.87      0.89      0.88      5000\n",
      "\n",
      "    accuracy                           0.88     10000\n",
      "   macro avg       0.88      0.88      0.88     10000\n",
      "weighted avg       0.88      0.88      0.88     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy on Test data\n",
    "'''\n",
    "prediction = model.predict(test_padded)\n",
    "\n",
    "'''\n",
    "# Get probabilities\n",
    "prediction = model.predict(test_padded)\n",
    "\n",
    "# Get labels based on probability 1 if p>= 0.5 else 0\n",
    "prediction = (prediction>=0.5)\n",
    "\n",
    "# Accuracy : one can use classification_report from sklearn\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(test_labels, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TIICV-ySOYL0"
   },
   "source": [
    "## Get predictions for random examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "m2RmfNL3OYL0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]\n",
      " [0]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "# reviews on which we need to predict\n",
    "sentence = [\"The movie was very touching and heart whelming\", \n",
    "            \"I have never seen a terrible movie like this\", \n",
    "            \"the movie plot is terrible but it had good acting\"]\n",
    "\n",
    "# convert to a sequence\n",
    "sequences = tokenizer.texts_to_sequences(sentence)\n",
    "\n",
    "# pad the sequence\n",
    "padded = pad_sequences(sequences, padding='post', maxlen=max_length)\n",
    "\n",
    "# Get probabilities\n",
    "pred = model.predict(padded)\n",
    "#print(model.predict(padded))\n",
    "\n",
    "# Get labels based on probability 1 if p>= 0.5 else 0\n",
    "pred = pred>=0.5 \n",
    "pred = pred +1 -1\n",
    "print(pred)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "NLP_CS60075_A21_Assn2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
